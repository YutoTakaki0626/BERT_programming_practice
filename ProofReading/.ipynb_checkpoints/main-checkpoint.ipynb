{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6209f06a-27f6-46dc-931d-9a144111e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6eddb60-a027-422b-9cd0-abe122a1c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.5.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: fugashi==1.1.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: ipadic==1.0.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.2.7 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (1.2.7)\n",
      "Requirement already satisfied: requests in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2.25.1)\n",
      "Requirement already satisfied: filelock in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.0.45)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (4.59.0)\n",
      "Requirement already satisfied: packaging in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2021.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (1.19.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.10.3)\n",
      "Requirement already satisfied: torch>=1.4 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (1.7.0)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.4.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (2.4.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.18.2)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.9.0)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (5.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (3.7.4.post0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.4.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.14.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.4->pytorch-lightning==1.2.7) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.4->pytorch-lightning==1.2.7) (0.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (1.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.0) (2.4.7)\n",
      "Requirement already satisfied: joblib in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (1.0.1)\n",
      "Requirement already satisfied: click in /Users/yuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bb845c-40ec-4832-b24d-5c7bcbe49048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015c3778-7f90-430e-a64a-35f3534c07fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'proofreading_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a50ec01656a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mproofreading_tokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSC_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSC_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'proofreading_tokenizer'"
     ]
    }
   ],
   "source": [
    "from proofreading_tokenizer import SC_tokenizer\n",
    "\n",
    "tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c758bad4-98fd-4d03-827d-886c074c3627",
   "metadata": {},
   "source": [
    "## encode_plus_tagged\n",
    "ファインチューニング時に使用。\n",
    "誤変換を含む文章と正しい文章を入力とし、\n",
    "符号化を行いBERTに入力できる形式にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6f5f1-89a1-4ec5-830b-ce1b07a8634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_text = '優勝トロフィーを変換した'\n",
    "correct_text = '優勝トロフィーを返還した'\n",
    "encoding = tokenizer.encode_plus_tagged(\n",
    "    wrong_text, correct_text, max_length=12\n",
    ")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f326aa-d9d4-44c3-8189-8101b2252444",
   "metadata": {},
   "source": [
    "## encode_plus_untagged\n",
    "文章を符号化し、それぞれのトークンの文章中の位置も特定しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51fd62-5f9c-4c43-abac-4862f993d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_text = '優勝トロフィーを変換した'\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    wrong_text, return_tensors='pt'\n",
    ")\n",
    "print('# encoding')\n",
    "print(encoding)\n",
    "print('# spans')\n",
    "print(spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebaab6-8bf1-475e-a1d2-4888efd603ee",
   "metadata": {},
   "source": [
    "## convert_bert_output_to_text\n",
    "推論時に使用。\n",
    "文章と、各トークンのラベルの予測値、文章中での位置を入力とする。\n",
    "そこから、BERTによって予測された文章に変換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e449d68-f545-4a15-903a-37dbfd6afeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [2, 759, 18204, 11, 8274, 15, 10, 3]\n",
    "predicted_text = tokenizer.convert_bert_output_to_text(\n",
    "    wrong_text, predicted_labels, spans\n",
    ")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cc69b-cb4f-4e25-939e-5cc21099012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mlm = BertForMaskedLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707357b-4d7f-46e9-87ad-03d9e311cb92",
   "metadata": {},
   "source": [
    "### 学習①"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1521c4-c98c-4f68-8751-178088bc8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '優勝トロフィーを変換した。'\n",
    "\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    text, return_tensors='pt'\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = bert_mlm(**encoding)\n",
    "    scores = output.logits\n",
    "    labels_predicted = scores[0].argmax(-1).numpy().tolist()\n",
    "    \n",
    "predict_text = tokenizer.convert_bert_output_to_text(\n",
    "    text, labels_predicted, spans\n",
    ")\n",
    "predict_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c47d92-9731-4172-9975-2a47ac17423c",
   "metadata": {},
   "source": [
    "### 学習②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0528a-fcec-4ae6-bb68-cf085384c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'wrong_text': '優勝トロフィーを変換した。',\n",
    "        'correct_text': '優勝トロフィーを返還した。',\n",
    "    },\n",
    "    {\n",
    "        'wrong_text': '人と森は強制している。',\n",
    "        'correct_text': '人と森は共生している。',\n",
    "    }\n",
    "]\n",
    "\n",
    "max_length=32\n",
    "dataset_for_loader = []\n",
    "for sample in data:\n",
    "    wrong_text = sample['wrong_text']\n",
    "    correct_text = sample['correct_text']\n",
    "    encoding = tokenizer.encode_plus_tagged(\n",
    "        wrong_text, correct_text, max_length=max_length\n",
    "    )\n",
    "    encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
    "    dataset_for_loader.append(encoding)\n",
    "    \n",
    "dataloader = DataLoader(dataset_for_loader, batch_size=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    encoding = { k: v for k, v in batch.items() }\n",
    "    output = bert_mlm(**encoding)\n",
    "    loss = output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c8a34-b323-44cc-b01e-f1cfe039022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://nlp.ist.i.kyoto-u.ac.jp/DLcounter/lime.cgi?down=https://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JWTD/jwtd.tar.gz&name=JWTD.tar.gz\" -o JWTD.tar.gz\n",
    "!tar zxvf JWTD.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b1ed9-022e-491f-bbdb-3a1915a5a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataset\n",
    "\n",
    "# データのロード\n",
    "train_df = pd.read_json(\n",
    "    './jwtd/train.jsonl', orient='records', lines=True\n",
    ")\n",
    "test_df = pd.read_json(\n",
    "    './jwtd/test.jsonl', orient='records', lines=True\n",
    ")\n",
    "\n",
    "print('学習と検証用のデータセット：')\n",
    "dataset = create_dataset(train_df)\n",
    "random.shuffle(dataset)\n",
    "n = len(dataset)\n",
    "n_train = int(n*0.8)\n",
    "dataset_train = dataset[:n_train]\n",
    "dataset_val = dataset[n_train:]\n",
    "\n",
    "print('テスト用のデータセット：')\n",
    "dataset_test = create_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f295ec-e1a5-44af-8887-9f08e6cf72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import create_dataset_for_loader\n",
    "\n",
    "tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# データセットの作成\n",
    "max_length = 32\n",
    "dataset_train_for_loader = create_dataset_for_loader(\n",
    "    tokenizer, dataset_train, max_length\n",
    ")\n",
    "dataset_val_for_loader = create_dataset_for_loader(\n",
    "    tokenizer, dataset_val, max_length\n",
    ")\n",
    "\n",
    "# データローダの作成\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3089d3-1e37-4792-bb33-7459d57d9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lightning_model import BertForMaskedLM_pl\n",
    "\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath='model/'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "model = BertForMaskedLM_pl(MODEL_NAME, lr=1e-5)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "best_model_path = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bec2f7-1505-4795-ac48-eba0c6549b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\n",
    "    'ユーザーの試行に合わせた楽曲を配信する。',\n",
    "    'メールに明日の会議の史料を添付した。',\n",
    "    '乳酸菌で牛乳を発行するとヨーグルトができる。',\n",
    "    '突然、子供が帰省を発した。'\n",
    "]\n",
    "\n",
    "tokenizer = SC_tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForMaskedLM_pl.load_from_checkpoint(best_model_path)\n",
    "bert_mlm = model.bert_mlm\n",
    "\n",
    "for text in text_list:\n",
    "    predict_text = predict(text, tokenizer, bert_mlm) # BERTによる予測\n",
    "    print('---')\n",
    "    print(f'入力：{text}')\n",
    "    print(f'出力：{predict_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc1860-f8c9-4f67-97a0-f333cc6a921d",
   "metadata": {},
   "source": [
    "### テストデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728583f-b881-421b-9198-0800ca94ac94",
   "metadata": {},
   "source": [
    "####　・予測が完全に一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b504d-0e70-4a3b-842c-1c6b74d27e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "for sample in tqdm(dataset_test):\n",
    "    wrong_text = sample['wrong_text']\n",
    "    correct_text = sample['correct_text']\n",
    "    predict_text = predict(wrong_text, tokenizer, bert_mlm)\n",
    "    \n",
    "    if correct_text == predicted_text:\n",
    "        correct_num += 1\n",
    "\n",
    "print(f'Accuracy: {correct_num/len(dataset_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af6985-167a-4ffe-88a0-0139ba89ad87",
   "metadata": {},
   "source": [
    "####　・誤変換の漢字の特定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ee35f-40f8-45ae-beaf-fbebcee7cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_position_num = 0\n",
    "for sample in tqdm(dataset_test):\n",
    "    wrong_text = sample['wrong_text']\n",
    "    correct_text = sample['correct_text']\n",
    "    \n",
    "    #符号化\n",
    "    encoding = tokenizer(wrong_text)\n",
    "    wrong_input_ids = encoding['input_ids']\n",
    "    correct_encoding = tokenizer(correct_text)\n",
    "    correct_input_ids = correct_encoding['input_ids']\n",
    "    \n",
    "    #予測\n",
    "    with torch.no_grad():\n",
    "        output = bert_mlm(**encoding)\n",
    "        scores = output.logits\n",
    "        predict_input_ids = scores[0].argmax(-1).numpy().tolist()\n",
    "        \n",
    "    #特殊トークン除去\n",
    "    wrong_input_ids = wrong_input_ids[1:-1]\n",
    "    correct_input_ids =  correct_input_ids[1:-1]\n",
    "    predict_input_ids =  predict_input_ids[1:-1]\n",
    "    \n",
    "    #特定\n",
    "    detect_flag = True\n",
    "    for wrong_token, correct_token, predict_token \\\n",
    "        in zip(wrong_input_ids, correct_input_ids, predict_input_ids):\n",
    "        \n",
    "        if wrong_token == correct_token: #正しいトークン\n",
    "            if wrong_token != predict_token:  #変換する必要ないのに変換した\n",
    "                detect_flag = False\n",
    "                break\n",
    "        else:\n",
    "            if wrong_token == predict_token: #誤変換トークン\n",
    "                detect_flag = False　#放置\n",
    "                break\n",
    "                \n",
    "    if detect_flag:\n",
    "        correct_position_num += 1\n",
    "        \n",
    "print(f'Accuracy: {correct_position_num/len(dataset_test):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22b972-0334-4c19-9887-dedae06398b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
